"""
age_utils â€” Apache AGE + KRX ê³µìš© ìœ í‹¸ë¦¬í‹°

age_backfill / age_sync_universe / age_tagging DAGì—ì„œ ê³µí†µìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” í•¨ìˆ˜ë“¤.
"""

import logging
import os

log = logging.getLogger(__name__)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ETF ìš´ìš©ì‚¬ ë§¤í•‘
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ETF_COMPANY_MAP = {
    # ì‚¼ì„±
    'KODEX': 'ì‚¼ì„±ìì‚°ìš´ìš©',
    'KoAct': 'ì‚¼ì„±ì•¡í‹°ë¸Œìì‚°ìš´ìš©',
    # ë¯¸ë˜ì—ì…‹
    'TIGER': 'ë¯¸ë˜ì—ì…‹ìì‚°ìš´ìš©',
    # KB
    'RISE': 'KBìì‚°ìš´ìš©',
    # í•œêµ­íˆ¬ì
    'ACE': 'í•œêµ­íˆ¬ìì‹ íƒìš´ìš©',
    # NHì•„ë¬¸ë””
    'HANARO': 'NHì•„ë¬¸ë””ìì‚°ìš´ìš©',
    # ì‹ í•œ
    'SOL': 'ì‹ í•œìì‚°ìš´ìš©',
    # í•œí™”
    'PLUS': 'í•œí™”ìì‚°ìš´ìš©',
    # í‚¤ì›€
    'KIWOOM': 'í‚¤ì›€ìì‚°ìš´ìš©',
    # í•˜ë‚˜
    '1Q': 'í•˜ë‚˜ìì‚°ìš´ìš©',
    # íƒ€ì„í´ë¦¬ì˜¤
    'TIMEFOLIO': 'íƒ€ì„í´ë¦¬ì˜¤ìì‚°ìš´ìš©',
    'TIME': 'íƒ€ì„í´ë¦¬ì˜¤ìì‚°ìš´ìš©',
    # ìš°ë¦¬
    'WON': 'ìš°ë¦¬ìì‚°ìš´ìš©',
    # ê¸°íƒ€
    'ë§ˆì´ë‹¤ìŠ¤': 'ë§ˆì´ë‹¤ìŠ¤ìì‚°ìš´ìš©',
    'íŒŒì›Œ': 'êµë³´ì•…ì‚¬ìì‚°ìš´ìš©',
    'BNK': 'BNKìì‚°ìš´ìš©',
    'DAISHIN343': 'ëŒ€ì‹ ìì‚°ìš´ìš©',
    'HK': 'í¥êµ­ìì‚°ìš´ìš©',
    'UNICORN': 'í˜„ëŒ€ìì‚°ìš´ìš©',
}


def get_company_from_etf_name(name: str) -> str:
    """ETF ì´ë¦„ì—ì„œ ìš´ìš©ì‚¬ ì¶”ì¶œ"""
    for prefix, company in ETF_COMPANY_MAP.items():
        if name.startswith(prefix):
            return company
    return 'ê¸°íƒ€'


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë£° ê¸°ë°˜ íƒœê·¸ ìƒìˆ˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

RULE_ONLY_TAGS = ['ì½”ìŠ¤í”¼200', 'ì½”ìŠ¤ë‹¥150']

# ì´ë¦„ì´ 200/200TR/150ìœ¼ë¡œ ëë‚˜ëŠ” ETFë§Œ ë§¤ì¹­ (TIGER 200 ì¤‘ê³µì—… ë“± ì„¹í„° ETF ì œì™¸)
INDEX_TAG_PATTERNS = [
    (r'(?<!\d)200(?:TR)?\s*$', 'ì½”ìŠ¤í”¼200'),
    (r'(?<!\d)200ì•¡í‹°ë¸Œ', 'ì½”ìŠ¤í”¼200'),
    (r'(?<!\d)150\s*$', 'ì½”ìŠ¤ë‹¥150'),
]


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# DB / AGE ì—°ê²°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def get_db_connection():
    """Get database connection"""
    import psycopg2
    from urllib.parse import urlparse

    db_url = os.environ.get(
        'DATABASE_URL',
        'postgresql://postgres:postgres@db:5432/etf_atlas'
    )

    parsed = urlparse(db_url)
    conn = psycopg2.connect(
        host=parsed.hostname or 'db',
        port=parsed.port or 5432,
        database=parsed.path.lstrip('/') or 'etf_atlas',
        user=parsed.username or 'postgres',
        password=parsed.password or 'postgres',
    )
    return conn


def init_age(conn):
    """Initialize Apache AGE for the connection"""
    cur = conn.cursor()
    cur.execute("LOAD 'age';")
    cur.execute("SET search_path = ag_catalog, '$user', public;")
    conn.commit()
    return cur


def execute_cypher(cur, cypher_query, params=None):
    """Execute Cypher query via Apache AGE"""
    if params:
        import re
        # ê¸´ í‚¤ë¶€í„° ì¹˜í™˜í•˜ì—¬ $codeê°€ $code_nameì„ ì¹¨ë²”í•˜ëŠ” ê²ƒì„ ë°©ì§€
        for key in sorted(params.keys(), key=len, reverse=True):
            value = params[key]
            if value is None:
                replacement = 'null'
            elif isinstance(value, bool):
                replacement = 'true' if value else 'false'
            elif isinstance(value, (int, float)):
                replacement = str(value)
            else:
                escaped = str(value).replace("\\", "\\\\").replace("'", "\\'").replace('"', '\\"')
                replacement = f"'{escaped}'"
            # ë‹¨ì–´ ê²½ê³„ë¥¼ ì‚¬ìš©í•˜ì—¬ ì •í™•í•œ íŒŒë¼ë¯¸í„°ë§Œ ì¹˜í™˜
            cypher_query = re.sub(rf'\${re.escape(key)}\b', replacement, cypher_query)

    sql = f"""
        SELECT * FROM cypher('etf_graph', $$
            {cypher_query}
        $$) as (result agtype);
    """
    cur.execute(sql)
    return cur.fetchall()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë°°ì¹˜ í—¬í¼
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _escape_cypher_value(value):
    """Cypher ë¦¬í„°ëŸ´ë¡œ ë³€í™˜"""
    if value is None:
        return 'null'
    if isinstance(value, bool):
        return 'true' if value else 'false'
    if isinstance(value, (int, float)):
        import math
        if math.isnan(value) or math.isinf(value):
            return 'null'
        return str(value)
    escaped = str(value).replace("\\", "\\\\").replace("'", "\\'").replace('"', '\\"')
    return f"'{escaped}'"


def build_cypher_list(items: list[dict]) -> str:
    """[{code: 'A'}, {code: 'B'}] í˜•íƒœì˜ Cypher ë¦¬ìŠ¤íŠ¸ ë¦¬í„°ëŸ´ ìƒì„±"""
    parts = []
    for item in items:
        props = ", ".join(
            f"{k}: {_escape_cypher_value(v)}" for k, v in item.items()
        )
        parts.append("{" + props + "}")
    return "[" + ", ".join(parts) + "]"


def execute_cypher_batch(cur, cypher_template: str, items: list[dict],
                         batch_size: int = 100):
    """UNWIND + cypher_templateë¡œ ë°°ì¹˜ ì‹¤í–‰.

    templateì—ì„œ 'item' ë³€ìˆ˜ë¥¼ ì‚¬ìš©.
    ì˜ˆ: MERGE (e:ETF {code: item.code}) RETURN e
    """
    if not items:
        return []

    all_results = []
    for i in range(0, len(items), batch_size):
        batch = items[i:i + batch_size]
        cypher_list = build_cypher_list(batch)
        query = f"UNWIND {cypher_list} AS item\n{cypher_template}"
        results = execute_cypher(cur, query)
        all_results.extend(results)
    return all_results


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# KRX ë°ì´í„° ì¡°íšŒ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def get_krx_daily_data(date: str) -> tuple[list, str]:
    """KRX Open APIì—ì„œ ETF ì¼ë³„ë§¤ë§¤ì •ë³´ ì¡°íšŒ (ìµœê·¼ ê±°ë˜ì¼ ìë™ íƒìƒ‰)

    Args:
        date: ê¸°ì¤€ì¼ì (YYYYMMDD í˜•ì‹)

    Returns:
        tuple: (ETFDailyData ë¦¬ìŠ¤íŠ¸, ì‹¤ì œ ì¡°íšŒëœ ë‚ ì§œ), ì‹¤íŒ¨ ì‹œ (ë¹ˆ ë¦¬ìŠ¤íŠ¸, ë¹ˆ ë¬¸ìì—´)
    """
    from datetime import datetime, timedelta
    from krx_api_client import KRXApiClient

    auth_key = os.environ.get('KRX_AUTH_KEY', '')
    if not auth_key:
        log.warning("KRX_AUTH_KEY not set, cannot fetch KRX data")
        return [], ''

    try:
        client = KRXApiClient(auth_key)

        base_date = datetime.strptime(date, '%Y%m%d')
        for i in range(7):
            check_date = (base_date - timedelta(days=i)).strftime('%Y%m%d')
            result = client.get_etf_daily_trading(check_date)
            if result:
                if i > 0:
                    log.info(f"No data for {date}, using latest trading day: {check_date}")
                return result, check_date

        log.warning(f"No trading data found within 7 days from {date}")
        return [], ''
    except Exception as e:
        log.error(f"Failed to get KRX daily data: {e}")
        return [], ''


def _get_krx_data_for_exact_date(date: str) -> list:
    """KRX APIì—ì„œ ì •í™•íˆ í•´ë‹¹ ë‚ ì§œì˜ ë°ì´í„°ë§Œ ì¡°íšŒ (ê±°ë˜ì¼ íƒìƒ‰ ì—†ìŒ)"""
    from krx_api_client import KRXApiClient

    auth_key = os.environ.get('KRX_AUTH_KEY', '')
    if not auth_key:
        return []

    try:
        client = KRXApiClient(auth_key)
        result = client.get_etf_daily_trading(date)
        return result if result else []
    except Exception as e:
        log.warning(f"Failed to get KRX data for {date}: {e}")
        return []


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ìœ ë‹ˆë²„ìŠ¤ í•„í„°ë§
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def get_valid_ticker_set(date: str) -> set:
    """KOSPI + KOSDAQ + ETF ìƒì¥ì¢…ëª© ì½”ë“œ ì§‘í•© ë°˜í™˜ (ì±„ê¶Œ/íŒŒìƒ/í˜„ê¸ˆ ë“± ì œì™¸ìš©)"""
    from pykrx import stock

    kospi = set(stock.get_market_ticker_list(date, market='KOSPI'))
    kosdaq = set(stock.get_market_ticker_list(date, market='KOSDAQ'))
    etfs = set(stock.get_etf_ticker_list(date))
    valid = kospi | kosdaq | etfs
    log.info(f"Valid tickers: KOSPI={len(kospi)}, KOSDAQ={len(kosdaq)}, "
             f"ETF={len(etfs)}, total={len(valid)}")
    return valid


def check_new_universe_candidates(krx_data_dicts: list, existing_codes: set) -> list:
    """ìƒˆë¡œìš´ ìœ ë‹ˆë²„ìŠ¤ í›„ë³´ ETF í™•ì¸

    ì¡°ê±´:
    - ê¸°ì¡´ ìœ ë‹ˆë²„ìŠ¤ì— ì—†ìŒ
    - ìˆœìì‚° 500ì–µ ì´ìƒ
    - ì œì™¸ í‚¤ì›Œë“œ ë¯¸í¬í•¨
    - í•´ì™¸ ê´€ë ¨ í‚¤ì›Œë“œ ë¯¸í¬í•¨
    """
    FOREIGN_NAME_KEYWORDS = [
        'ë¯¸êµ­', 'ì¤‘êµ­', 'ì°¨ì´ë‚˜', 'ì¼ë³¸', 'ì¸ë„', 'ë² íŠ¸ë‚¨', 'ëŒ€ë§Œ', 'ìœ ëŸ½', 'ë…ì¼',
        'ê¸€ë¡œë²Œ', 'Global', 'China', 'Japan', 'India', ' US', 'USA',
        'S&P', 'NASDAQ', 'ë‚˜ìŠ¤ë‹¥', 'ë‹¤ìš°ì¡´ìŠ¤',
        'MSCI', 'ì„ ì§„êµ­', 'ì‹ í¥êµ­', 'ì•„ì‹œì•„',
        'í…ŒìŠ¬ë¼', 'Tesla', 'ì—”ë¹„ë””ì•„', 'NVIDIA', 'êµ¬ê¸€', 'Google',
        'ì• í”Œ', 'Apple', 'ì•„ë§ˆì¡´', 'Amazon', 'íŒ”ë€í‹°ì–´', 'Palantir',
        'ë¸Œë¡œë“œì»´', 'Broadcom', 'ì•Œë¦¬ë°”ë°”', 'Alibaba', 'ë²„í¬ì…”', 'Berkshire',
        'ì›”ë“œ', 'World', 'êµ­ì œê¸ˆ', 'ê¸ˆì•¡í‹°ë¸Œ',
    ]

    EXCLUDE_KEYWORDS = [
        'ë ˆë²„ë¦¬ì§€', 'ì¸ë²„ìŠ¤', '2X', 'ê³±ë²„ìŠ¤', '2ë°°', '3ë°°',
        'í•©ì„±', 'ì„ ë¬¼', 'íŒŒìƒ', 'synthetic', 'í˜¼í•©',
        'ì»¤ë²„ë“œì½œ', 'ì»¤ë²„ë“œ', 'covered', 'í”„ë¦¬ë¯¸ì—„',
        'ì±„ê¶Œ', 'êµ­ì±„', 'íšŒì‚¬ì±„', 'í¬ë ˆë”§', 'ê¸ˆë¦¬', 'êµ­ê³µì±„', 'ë‹¨ê¸°ì±„', 'ì¥ê¸°ì±„',
        'ê¸ˆìœµì±„', 'íŠ¹ìˆ˜ì±„', 'TDF', 'ì „ë‹¨ì±„', 'ì€í–‰ì±„',
        'êµ­ê³ ì±„', 'TRF',
        'ê¸ˆí˜„ë¬¼', 'ê³¨ë“œ', 'gold', 'ì€í˜„ë¬¼', 'ì‹¤ë²„', 'silver', 'ì›ìœ ', 'WTI', 'êµ¬ë¦¬', 'ì›ìì¬',
        'ë‹¬ëŸ¬', 'ì—”í™”', 'ìœ ë¡œ', 'ì›í™”', 'í†µí™”', 'USD', 'JPY', 'EUR',
        'ë¨¸ë‹ˆë§ˆì¼“', 'CD', 'ë‹¨ê¸°', 'MMF', 'CMA',
        'ë¦¬ì¸ ', 'REITs', 'REIT',
    ]

    MIN_AUM = 500 * 100_000_000  # 500ì–µ

    candidates = []
    for item in krx_data_dicts:
        code = item['code']
        if code in existing_codes:
            continue

        name = item['name']
        name_lower = name.lower()
        net_assets = item.get('net_assets', 0)

        if net_assets < MIN_AUM:
            continue
        if any(kw.lower() in name_lower for kw in EXCLUDE_KEYWORDS):
            continue
        if any(kw.lower() in name_lower or kw in name for kw in FOREIGN_NAME_KEYWORDS):
            continue

        candidates.append({
            'code': code,
            'name': name,
            'index_name': '',
            'net_assets': net_assets
        })

    return candidates


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# AGE ê³µìš© ì¡°íšŒ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _parse_age_value(raw):
    """AGE agtype ë¬¸ìì—´ì—ì„œ íƒ€ì… ì ‘ë¯¸ì‚¬ ì œê±°"""
    import re
    raw = str(raw)
    raw = re.sub(r'::(?:numeric|integer|float|vertex|edge|path|text|boolean)\b', '', raw)
    return raw.strip('"')


def get_business_days(from_date: str, to_date: str) -> list[str]:
    """pykrxë¡œ ì˜ì—…ì¼ ëª©ë¡ ì¡°íšŒ. YYYYMMDD ë¦¬ìŠ¤íŠ¸ ë°˜í™˜."""
    from pykrx import stock
    business_days = stock.get_previous_business_days(fromdate=from_date, todate=to_date)
    return [d.strftime('%Y%m%d') for d in business_days]


def get_last_collected_date() -> str | None:
    """AGEì—ì„œ ë§ˆì§€ë§‰ ìˆ˜ì§‘ëœ Price ë‚ ì§œ ì¡°íšŒ. YYYYMMDD ë˜ëŠ” None."""
    conn = get_db_connection()
    cur = init_age(conn)
    try:
        results = execute_cypher(cur, """
            MATCH (e:ETF)-[:HAS_PRICE]->(p:Price)
            RETURN p.date
            ORDER BY p.date DESC
            LIMIT 1
        """)
        if results and results[0][0]:
            raw = _parse_age_value(results[0][0])
            if raw and raw != 'null':
                return raw.replace('-', '')
        return None
    except Exception as e:
        log.warning(f"Failed to query last collected date: {e}")
        return None
    finally:
        cur.close()
        conn.close()


def get_previous_holds_date(before_date: str) -> str | None:
    """AGEì—ì„œ before_date ì´ì „ì˜ ê°€ì¥ ìµœê·¼ HOLDS ë‚ ì§œ ì¡°íšŒ.

    Args:
        before_date: ê¸°ì¤€ì¼ (YYYY-MM-DD í˜•ì‹)

    Returns:
        YYYYMMDD ë¬¸ìì—´ ë˜ëŠ” None
    """
    conn = get_db_connection()
    cur = init_age(conn)
    try:
        results = execute_cypher(cur, """
            MATCH ()-[h:HOLDS]->()
            WHERE h.date < $before_date
            WITH DISTINCT h.date AS d
            RETURN d
            ORDER BY d DESC
            LIMIT 1
        """, {'before_date': before_date})
        if results and results[0][0]:
            raw = _parse_age_value(results[0][0])
            if raw and raw != 'null':
                return raw.replace('-', '')
        return None
    except Exception as e:
        log.warning(f"Failed to query previous holds date: {e}")
        return None
    finally:
        cur.close()
        conn.close()


def get_etf_codes_from_age() -> set[str]:
    """AGEì—ì„œ ETF ìœ ë‹ˆë²„ìŠ¤ ì½”ë“œ ì¡°íšŒ."""
    conn = get_db_connection()
    cur = init_age(conn)
    try:
        results = execute_cypher(cur, "MATCH (e:ETF) RETURN e.code")
        codes = set()
        for row in results:
            if row[0]:
                code = _parse_age_value(row[0])
                if code:
                    codes.add(code)
        return codes
    finally:
        cur.close()
        conn.close()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ê³µìš© ìˆ˜ì§‘ í•¨ìˆ˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def collect_universe_and_prices(dates: list[str]) -> tuple[set[str], list[dict]]:
    """ë‚ ì§œë³„ KRX ë°ì´í„° â†’ ETF ë…¸ë“œ + ë©”íƒ€ë°ì´í„°(ë³´ìˆ˜ìœ¨/ìš´ìš©ì‚¬) + Price ë…¸ë“œ ìƒì„±.

    Returns:
        (universe_codes, new_etfs_list)
    """
    from pykrx.website.krx.etx.core import ETF_ì „ì¢…ëª©ê¸°ë³¸ì¢…ëª©
    from math import ceil

    if not dates:
        return get_etf_codes_from_age(), []

    existing_codes = get_etf_codes_from_age()
    all_new_etfs = []

    # ë³´ìˆ˜ìœ¨ ì¼ê´„ ì¡°íšŒ
    fee_map = {}
    try:
        fee_df = ETF_ì „ì¢…ëª©ê¸°ë³¸ì¢…ëª©().fetch()
        for _, row in fee_df.iterrows():
            code = row['ISU_SRT_CD']
            try:
                raw = float(row['ETF_TOT_FEE'])
                fee_map[code] = ceil(raw * 100) / 100
            except (ValueError, TypeError):
                pass
        log.info(f"Loaded expense ratio for {len(fee_map)} ETFs")
    except Exception as e:
        log.warning(f"Failed to fetch ETF fee data: {e}")

    conn = get_db_connection()
    cur = init_age(conn)
    total_prices = 0

    try:
        for bd in dates:
            krx_items = _get_krx_data_for_exact_date(bd)
            if not krx_items:
                continue

            # â”€â”€ ì‹ ê·œ ETF ë…¸ë“œ + ë©”íƒ€ë°ì´í„° â”€â”€
            krx_dicts = [{'code': item.code, 'name': item.name,
                          'net_assets': item.net_assets} for item in krx_items]
            new_candidates = check_new_universe_candidates(krx_dicts, existing_codes)

            if new_candidates:
                items = [{'code': c['code']} for c in new_candidates]
                execute_cypher_batch(cur, """
                    MERGE (e:ETF {code: item.code}) RETURN e
                """, items)

                # name + expense_ratio
                with_fee = [{'code': c['code'], 'name': c['name'],
                             'expense_ratio': fee_map[c['code']]}
                            for c in new_candidates if c['code'] in fee_map]
                no_fee = [{'code': c['code'], 'name': c['name']}
                          for c in new_candidates if c['code'] not in fee_map]

                if with_fee:
                    execute_cypher_batch(cur, """
                        MATCH (e:ETF {code: item.code})
                        SET e.name = item.name, e.expense_ratio = item.expense_ratio
                        RETURN e
                    """, with_fee)
                if no_fee:
                    execute_cypher_batch(cur, """
                        MATCH (e:ETF {code: item.code})
                        SET e.name = item.name
                        RETURN e
                    """, no_fee)

                # Company + MANAGED_BY
                seen_companies = set()
                company_items = []
                etf_company_pairs = []
                for c in new_candidates:
                    company = get_company_from_etf_name(c['name'])
                    if company not in seen_companies:
                        company_items.append({'name': company})
                        seen_companies.add(company)
                    etf_company_pairs.append({'code': c['code'], 'company': company})

                if company_items:
                    execute_cypher_batch(cur, """
                        MERGE (c:Company {name: item.name}) RETURN c
                    """, company_items)
                if etf_company_pairs:
                    execute_cypher_batch(cur, """
                        MATCH (e:ETF {code: item.code})
                        MATCH (c:Company {name: item.company})
                        MERGE (e)-[:MANAGED_BY]->(c)
                        RETURN 1
                    """, etf_company_pairs)

                conn.commit()
                for c in new_candidates:
                    existing_codes.add(c['code'])
                all_new_etfs.extend([{'code': c['code'], 'name': c['name']}
                                     for c in new_candidates])
                log.info(f"[{bd}] Added {len(new_candidates)} new ETFs with metadata")

            # â”€â”€ Price ë…¸ë“œ (ìœ ë‹ˆë²„ìŠ¤ë§Œ) â”€â”€
            date_str = f"{bd[:4]}-{bd[4:6]}-{bd[6:8]}"
            price_items = []
            for item in krx_items:
                if item.code not in existing_codes:
                    continue
                price_items.append({
                    'code': item.code, 'date': date_str,
                    'open': item.open_price, 'high': item.high_price,
                    'low': item.low_price, 'close': item.close_price,
                    'volume': item.volume, 'nav': item.nav,
                    'market_cap': item.market_cap, 'net_assets': item.net_assets,
                    'trade_value': item.trade_value,
                })

            if price_items:
                execute_cypher_batch(cur, """
                    MATCH (e:ETF {code: item.code})
                    MERGE (e)-[:HAS_PRICE]->(p:Price {date: item.date})
                    RETURN p
                """, price_items)
                execute_cypher_batch(cur, """
                    MATCH (e:ETF {code: item.code})-[:HAS_PRICE]->(p:Price {date: item.date})
                    SET p.open = item.open, p.high = item.high, p.low = item.low,
                        p.close = item.close, p.volume = item.volume, p.nav = item.nav,
                        p.market_cap = item.market_cap, p.net_assets = item.net_assets,
                        p.trade_value = item.trade_value
                    RETURN p
                """, price_items)

                valid_na = [it for it in price_items
                            if it.get('net_assets') and it['net_assets'] > 0]
                if valid_na:
                    execute_cypher_batch(cur, """
                        MATCH (e:ETF {code: item.code})
                        SET e.net_assets = item.net_assets
                        RETURN e
                    """, valid_na)

                conn.commit()
                total_prices += len(price_items)
                log.info(f"[{bd}] {len(price_items)} ETF prices saved")

        log.info(f"Universe & prices: {len(existing_codes)} ETFs, "
                 f"{total_prices} price records")
        return existing_codes, all_new_etfs

    finally:
        cur.close()
        conn.close()


def collect_holdings_for_dates(etf_codes: list[str], dates: list[str]):
    """ë‚ ì§œë³„ HOLDS ì—£ì§€ + Stock ë…¸ë“œ(ì´ë¦„/is_etf í¬í•¨) ë°°ì¹˜ ìƒì„±."""
    from pykrx import stock as pykrx_stock
    import pandas as pd
    import time
    from itertools import groupby

    if not etf_codes or not dates:
        return

    known_stocks = set()  # ì´ë¦„ ì¡°íšŒ ì™„ë£Œëœ Stock ì½”ë“œ ì¶”ì 
    total_holds = 0

    for bd in dates:
        date_str = f"{bd[:4]}-{bd[4:6]}-{bd[6:8]}"
        valid_tickers = get_valid_ticker_set(bd)

        all_holds = []
        all_stock_codes = set()

        for ticker in etf_codes:
            try:
                df = pykrx_stock.get_etf_portfolio_deposit_file(ticker, bd)
                if df is not None and not df.empty:
                    df = df[~df.index.astype(str).isin(['010010'])]  # ì„¤ì •í˜„ê¸ˆì•¡ ì œì™¸
                    df = df[df.index.astype(str).isin(valid_tickers)]
                    if 'ë¹„ì¤‘' in df.columns:
                        df = df.sort_values('ë¹„ì¤‘', ascending=False).head(30)
                    else:
                        df = df.head(30)

                    for idx, row in df.iterrows():
                        stock_code = str(idx)
                        if not stock_code:
                            continue
                        weight = float(row.get('ë¹„ì¤‘', 0))
                        shares_val = row.get('ê³„ì•½ìˆ˜', row.get('ì£¼ìˆ˜', 0))
                        shares = int(shares_val) if shares_val and not pd.isna(shares_val) else 0
                        all_holds.append({
                            'etf_code': ticker, 'stock_code': stock_code,
                            'date': date_str, 'weight': weight, 'shares': shares,
                        })
                        all_stock_codes.add(stock_code)

                time.sleep(0.1)
            except Exception as e:
                log.warning(f"Failed PDF for {ticker} on {bd}: {e}")

        if not all_holds:
            log.info(f"[{bd}] No holdings data, skipping")
            continue

        conn = get_db_connection()
        cur = init_age(conn)

        try:
            # Stock ë…¸ë“œ MERGE
            if all_stock_codes:
                stock_items = [{'code': c} for c in all_stock_codes]
                execute_cypher_batch(cur, """
                    MERGE (s:Stock {code: item.code}) RETURN s
                """, stock_items)

                # ì‹ ê·œ Stockë§Œ ì´ë¦„ ì¡°íšŒ + is_etf ì„¤ì •
                new_stocks = all_stock_codes - known_stocks
                if new_stocks:
                    etf_tickers = set(pykrx_stock.get_etf_ticker_list(bd))
                    name_items = []
                    for code in new_stocks:
                        try:
                            is_etf = code in etf_tickers
                            if is_etf:
                                name = str(pykrx_stock.get_etf_ticker_name(code))
                            else:
                                name = str(pykrx_stock.get_market_ticker_name(code))
                            if not name or isinstance(name, pd.DataFrame):
                                name = code
                        except Exception:
                            name = code
                            is_etf = code in etf_tickers
                        name_items.append({'code': code, 'name': name, 'is_etf': is_etf})

                    execute_cypher_batch(cur, """
                        MATCH (s:Stock {code: item.code})
                        SET s.name = item.name, s.is_etf = item.is_etf
                        RETURN s
                    """, name_items)
                    known_stocks.update(new_stocks)

                # is_etf IS NULL safety net (ê¸°ì¡´ Stock)
                execute_cypher_batch(cur, """
                    MATCH (s:Stock {code: item.code})
                    WHERE s.is_etf IS NULL
                    SET s.is_etf = false
                    RETURN s
                """, stock_items)
                conn.commit()

            # HOLDS ë°°ì¹˜
            holds_sorted = sorted(all_holds, key=lambda x: x['etf_code'])
            COMMIT_EVERY = 50
            etf_groups = []
            for etf_code, group in groupby(holds_sorted, key=lambda x: x['etf_code']):
                etf_groups.append((etf_code, list(group)))

            for i in range(0, len(etf_groups), COMMIT_EVERY):
                batch_groups = etf_groups[i:i + COMMIT_EVERY]
                batch_items = [item for _, items in batch_groups for item in items]
                try:
                    execute_cypher_batch(cur, """
                        MATCH (e:ETF {code: item.etf_code})
                        MATCH (s:Stock {code: item.stock_code})
                        MERGE (e)-[h:HOLDS {date: item.date}]->(s)
                        RETURN h
                    """, batch_items)
                    execute_cypher_batch(cur, """
                        MATCH (e:ETF {code: item.etf_code})-[h:HOLDS {date: item.date}]->(s:Stock {code: item.stock_code})
                        SET h.weight = item.weight, h.shares = item.shares
                        RETURN h
                    """, batch_items)
                    conn.commit()
                except Exception as e:
                    log.warning(f"Failed HOLDS batch for {bd} at group {i}: {e}")
                    conn.rollback()
                    cur = init_age(conn)

            total_holds += len(all_holds)
            log.info(f"[{bd}] {len(all_holds)} HOLDS edges "
                     f"({len(all_stock_codes)} stocks)")

        finally:
            cur.close()
            conn.close()

    log.info(f"Holdings complete: {total_holds} edges across {len(dates)} dates")


def collect_stock_prices_for_dates(dates: list[str]):
    """ë‚ ì§œë³„ Stock ê°€ê²© ë°°ì¹˜ ì €ì¥."""
    from pykrx import stock as pykrx_stock

    if not dates:
        return

    # is_etf=false Stock ì½”ë“œ ì¡°íšŒ
    conn = get_db_connection()
    cur = init_age(conn)
    try:
        results = execute_cypher(cur, """
            MATCH (s:Stock) WHERE s.is_etf = false RETURN s.code
        """, {})
        stock_codes = set()
        for row in results:
            if row[0]:
                code = _parse_age_value(row[0])
                if code:
                    stock_codes.add(code)
    finally:
        cur.close()
        conn.close()

    if not stock_codes:
        log.warning("No Stock nodes for price collection")
        return

    log.info(f"Collecting prices for {len(stock_codes)} stocks "
             f"across {len(dates)} dates")
    total_success = 0

    for bd in dates:
        conn = get_db_connection()
        cur = init_age(conn)
        try:
            date_str = f"{bd[:4]}-{bd[4:6]}-{bd[6:8]}"
            df = pykrx_stock.get_market_ohlcv_by_ticker(bd)
            if df is None or df.empty:
                continue

            items = []
            for code in stock_codes:
                if code in df.index:
                    row = df.loc[code]
                    items.append({
                        'code': code, 'date': date_str,
                        'open': float(row.get('ì‹œê°€', 0)),
                        'high': float(row.get('ê³ ê°€', 0)),
                        'low': float(row.get('ì €ê°€', 0)),
                        'close': float(row.get('ì¢…ê°€', 0)),
                        'volume': int(row.get('ê±°ë˜ëŸ‰', 0)),
                        'change_rate': float(row.get('ë“±ë½ë¥ ', 0)),
                    })

            if not items:
                continue

            execute_cypher_batch(cur, """
                MATCH (s:Stock {code: item.code})
                MERGE (s)-[:HAS_PRICE]->(p:Price {date: item.date})
                RETURN p
            """, items)
            execute_cypher_batch(cur, """
                MATCH (s:Stock {code: item.code})-[:HAS_PRICE]->(p:Price {date: item.date})
                SET p.open = item.open, p.high = item.high, p.low = item.low,
                    p.close = item.close, p.volume = item.volume,
                    p.change_rate = item.change_rate
                RETURN p
            """, items)

            conn.commit()
            total_success += len(items)
            log.info(f"[{bd}] {len(items)} stock prices saved")
        except Exception as e:
            log.warning(f"Failed stock prices for {bd}: {e}")
        finally:
            cur.close()
            conn.close()

    log.info(f"Stock prices complete: {total_success} records")


def record_collection_run(date_str: str):
    """collection_runs í…Œì´ë¸”ì— ìˆ˜ì§‘ ì™„ë£Œ ê¸°ë¡."""
    conn = get_db_connection()
    cur = conn.cursor()
    try:
        cur.execute(
            "INSERT INTO collection_runs (collected_at) VALUES (%s) "
            "ON CONFLICT (collected_at) DO NOTHING",
            (date_str,)
        )
        conn.commit()
        log.info(f"Collection run recorded: {date_str}")
    finally:
        cur.close()
        conn.close()


def send_discord_notification(date_str: str):
    """admin ìœ ì €ì˜ ì¦ê²¨ì°¾ê¸° ê¸°ë°˜ ë¹„ì¤‘ë³€í™”ë¥¼ ë””ìŠ¤ì½”ë“œë¡œ ë°œì†¡."""
    import httpx
    import json

    webhook_url = os.environ.get('DISCORD_WEBHOOK_URL')
    if not webhook_url:
        log.info("DISCORD_WEBHOOK_URL not set â€” skipping Discord notification")
        return

    conn = get_db_connection()
    cur = init_age(conn)

    try:
        # admin ìœ ì € ì¡°íšŒ
        results = execute_cypher(cur, """
            MATCH (u:User {role: 'admin'})-[:WATCHES]->(e:ETF)
            RETURN {user_id: u.user_id, etf_code: e.code, etf_name: e.name}
        """, {})

        if not results:
            log.info("No admin watches found â€” skipping Discord notification")
            return

        watches = []
        for row in results:
            raw = _parse_age_value(row[0])
            data = json.loads(raw)
            watches.append(data)

        # ì „ì¼ HOLDS ë‚ ì§œ ì¡°íšŒ
        if watches:
            first_etf = watches[0]['etf_code']
            prev_results = execute_cypher(cur, """
                MATCH (e:ETF {code: $code})-[h:HOLDS]->(:Stock)
                WITH DISTINCT h.date as d
                WHERE d < $date
                RETURN {date: d}
                ORDER BY d DESC
                LIMIT 1
            """, {'code': first_etf, 'date': date_str})
            prev_date = None
            if prev_results:
                raw = _parse_age_value(prev_results[0][0])
                prev_data = json.loads(raw)
                prev_date = prev_data.get('date')

        if not prev_date:
            log.info("No previous date found â€” skipping Discord notification")
            return

        # ETFë³„ ë¹„ì¤‘ë³€í™” ìˆ˜ì§‘
        changes_summary = []
        for w in watches:
            etf_code = w['etf_code']
            etf_name = w['etf_name']

            # í˜„ì¬ ë‚ ì§œ holdings
            today_h = _query_holdings(cur, etf_code, date_str)
            prev_h = _query_holdings(cur, etf_code, prev_date)

            if not today_h or not prev_h:
                continue

            etf_changes = []
            all_codes = set(today_h.keys()) | set(prev_h.keys())
            for code in all_codes:
                curr = today_h.get(code)
                prev = prev_h.get(code)
                cw = curr['weight'] if curr else 0
                pw = prev['weight'] if prev else 0
                diff = cw - pw

                if abs(diff) <= 3:
                    continue

                if curr and not prev:
                    ct = "ì‹ ê·œí¸ì…"
                elif prev and not curr:
                    ct = "í¸ì¶œ"
                elif diff > 0:
                    ct = "ì¦ê°€"
                else:
                    ct = "ê°ì†Œ"

                name = (curr or prev)['name']
                etf_changes.append(f"  {ct} {name}: {pw:.1f}% â†’ {cw:.1f}% ({diff:+.1f}%p)")

            if etf_changes:
                changes_summary.append(f"**{etf_name}** ({etf_code})\n" + "\n".join(etf_changes))

        if not changes_summary:
            log.info("No significant changes â€” skipping Discord notification")
            return

        # ë””ìŠ¤ì½”ë“œ ë©”ì‹œì§€ ë°œì†¡
        message = f"ğŸ“Š **ETF ë¹„ì¤‘ ë³€í™” ì•Œë¦¼** ({date_str})\n\n" + "\n\n".join(changes_summary)

        with httpx.Client() as client:
            resp = client.post(webhook_url, json={"content": message})
            resp.raise_for_status()

        log.info(f"Discord notification sent: {len(changes_summary)} ETFs with changes")

    except Exception as e:
        log.warning(f"Discord notification failed: {e}")
    finally:
        cur.close()
        conn.close()


def update_etf_returns():
    """ETF 1D/1W/1M ìˆ˜ìµë¥  ê³„ì‚° ë° ì €ì¥."""
    import json
    from collections import defaultdict
    from datetime import datetime, timedelta

    conn = get_db_connection()
    cur = init_age(conn)

    try:
        # ì „ì²´ ETFì˜ ìµœê·¼ 45ì¼ ê°€ê²©ì„ í•œ ë²ˆì— ì¡°íšŒ
        rows = execute_cypher(cur, """
            MATCH (e:ETF)-[:HAS_PRICE]->(p:Price)
            WITH e.code AS code, p.date AS date, p.close AS close, p.market_cap AS market_cap
            ORDER BY date DESC
            RETURN {code: code, date: date, close: close, market_cap: market_cap}
        """)

        if not rows:
            log.warning("No price data for returns calculation")
            return

        # ETFë³„ ê°€ê²© ê·¸ë£¹í•‘ (ìµœê·¼ 45ê°œë§Œ)
        etf_prices = defaultdict(list)
        for r in rows:
            if not r[0]:
                continue
            parsed = json.loads(_parse_age_value(r[0]))
            if parsed.get('close') is not None and parsed.get('date') is not None:
                code = parsed['code']
                if len(etf_prices[code]) < 45:
                    etf_prices[code].append(parsed)

        log.info(f"Calculating returns for {len(etf_prices)} ETFs")
        update_items = []

        for code, prices in etf_prices.items():
            try:
                if not prices:
                    continue

                latest_close = float(prices[0]['close'])
                if latest_close == 0:
                    continue

                latest_date = datetime.strptime(prices[0]['date'], '%Y-%m-%d')
                target_1w = (latest_date - timedelta(days=7)).strftime('%Y-%m-%d')
                target_1m = (latest_date - timedelta(days=30)).strftime('%Y-%m-%d')

                item = {
                    'code': code, 'close_price': latest_close,
                    'return_1d': None, 'return_1w': None, 'return_1m': None,
                    'market_cap_change_1w': None,
                }

                if len(prices) > 1:
                    prev = float(prices[1]['close'])
                    if prev > 0:
                        item['return_1d'] = round((latest_close - prev) / prev * 100, 2)

                for p in prices[1:]:
                    if p['date'] <= target_1w:
                        prev = float(p['close'])
                        if prev > 0:
                            item['return_1w'] = round((latest_close - prev) / prev * 100, 2)
                        latest_mc = prices[0].get('market_cap')
                        prev_mc = p.get('market_cap')
                        if latest_mc and prev_mc:
                            item['market_cap_change_1w'] = round(
                                (float(latest_mc) - float(prev_mc)) / float(prev_mc) * 100, 2)
                        break

                for p in prices[1:]:
                    if p['date'] <= target_1m:
                        prev = float(p['close'])
                        if prev > 0:
                            item['return_1m'] = round((latest_close - prev) / prev * 100, 2)
                        break

                update_items.append(item)
            except Exception as e:
                log.warning(f"Failed returns for {code}: {e}")

        if update_items:
            execute_cypher_batch(cur, """
                MATCH (e:ETF {code: item.code})
                SET e.close_price = item.close_price,
                    e.return_1d = item.return_1d,
                    e.return_1w = item.return_1w,
                    e.return_1m = item.return_1m,
                    e.market_cap_change_1w = item.market_cap_change_1w
                RETURN e
            """, update_items)
            conn.commit()
            log.info(f"Updated returns for {len(update_items)} ETFs")
        else:
            log.warning("No return data to update")

    finally:
        cur.close()
        conn.close()
