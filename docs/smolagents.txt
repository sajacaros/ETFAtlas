smolagents 소개 및 활용 가이드
- ETF Atlas 프로젝트 적용 사례와 LangChain 비교 -


smolagents란 무엇인가

AI 에이전트라는 개념이 점점 보편화되면서, 이를 쉽게 구현할 수 있는 프레임워크에 대한 수요도 함께 커지고 있다. LangChain, CrewAI, AutoGen 같은 프레임워크들이 이미 시장에 자리를 잡고 있는 가운데, 2025년 초 Hugging Face가 smolagents라는 이름의 새로운 라이브러리를 공개했다. 이름부터 흥미롭다. "Smol"은 인터넷 슬랭으로 "작은"이라는 뜻인데, 말 그대로 작고 가벼운 에이전트 프레임워크를 지향한다는 선언이다.

smolagents는 transformers.agents의 후속 프로젝트로 탄생했다. Hugging Face의 Aymeric Roucher, Thomas Wolf 등이 주도하여 개발했으며, 핵심 철학은 놀라울 정도로 명확하다. "단순함이 최고의 가치다." 전체 에이전트 로직이 약 1,000줄의 Python 코드로 구성되어 있다는 사실이 이 철학을 가장 잘 보여준다. 수만 줄에 달하는 다른 프레임워크와 비교하면 극단적으로 간결한 수준이다. 불필요한 추상화 계층을 걷어내고, 에이전트가 정말로 필요로 하는 것만 남겨두었다.

그렇다면 에이전트란 정확히 무엇일까. smolagents는 에이전시(agency)를 이진적인 개념이 아니라 스펙트럼으로 바라본다. 가장 낮은 수준에서는 LLM의 출력이 프로그램 흐름에 아무런 영향을 미치지 않는다. 단순히 텍스트를 생성해서 돌려주는 것이다. 한 단계 올라가면 LLM이 if/else 같은 기본적인 분기를 결정하는 라우터 역할을 한다. 그 다음은 LLM이 어떤 함수를 호출할지 결정하는 도구 호출 단계다. 더 위로 가면 LLM이 반복할지 멈출지를 스스로 판단하는 멀티스텝 에이전트가 되고, 최상위에서는 에이전트가 다른 에이전트를 호출하는 멀티 에이전트 시스템이 된다. smolagents의 CodeAgent는 이 스펙트럼에서 멀티스텝 에이전트 수준에 해당한다. 여러 단계에 걸쳐 도구를 호출하고, 그 결과를 관찰한 뒤, 다음에 무엇을 할지 스스로 결정한다.

동작 방식을 좀 더 구체적으로 살펴보면, 에이전트는 하나의 루프로 작동한다. 사용자의 질문이 메모리에 들어가고, LLM이 "아직 더 해야 할 일이 있는가"를 판단한다. 할 일이 남아 있다면 다음 행동을 결정하고, 그 행동을 실행한 뒤, 결과를 메모리에 추가한다. 이 과정을 충분한 답변이 만들어질 때까지 반복하고, 최종적으로 final_answer()를 호출하여 사용자에게 답변을 돌려준다. 단순한 구조이지만, 이 루프 안에서 에이전트는 상당히 복잡한 추론과 도구 활용을 수행할 수 있다.


코드 에이전트라는 핵심 아이디어

smolagents를 다른 프레임워크와 가장 뚜렷하게 구분짓는 특징은 코드 에이전트(Code Agent)라는 개념이다. 대부분의 에이전트 프레임워크에서는 LLM이 도구를 호출할 때 JSON 형태의 구조화된 데이터를 생성한다. 예를 들어 "search 도구를 호출하되 query 파라미터는 '삼성전자'로 해라"라는 의도를 JSON 블럽으로 표현하고, 프레임워크가 이를 파싱하여 실제 함수를 호출하는 방식이다. smolagents는 이 과정을 근본적으로 다르게 접근한다. LLM이 직접 Python 코드를 작성하고, 그 코드를 실행한다.

이 접근이 왜 강력한지 생각해보면 꽤 납득이 간다. 프로그래밍 언어는 애초에 컴퓨터가 수행할 행동을 표현하기 위해 만들어진 것이다. JSON으로 도구 호출을 기술하는 것은 결국 코드로 변환되어야 할 중간 표현에 불과하다. 그렇다면 처음부터 코드로 작성하는 것이 더 자연스럽지 않을까. 게다가 LLM은 대규모 코드 데이터셋으로 학습되어 있어서 코드 생성에 이미 상당히 능숙하다. 변수를 선언하고, 함수를 중첩 호출하고, 조건 분기를 넣고, 반복문을 돌리는 것이 코드에서는 지극히 자연스러운 일이다. JSON으로 이런 복잡한 로직을 표현하려면 상당히 번거로워진다.

Hugging Face 팀이 수행한 벤치마크에서도 이를 뒷받침하는 결과가 나왔다. CodeAgent는 동일한 작업을 수행할 때 JSON 기반의 ToolCallingAgent보다 평균 약 30% 적은 스텝으로 완료했으며, 전반적인 성공률도 더 높았다. 물론 smolagents도 ToolCallingAgent를 지원하기는 한다. OpenAI나 Anthropic의 표준 도구 호출 형식과 호환되는 JSON 기반 에이전트도 만들 수 있다. 하지만 프레임워크의 정체성은 분명히 CodeAgent에 있다.

보안 측면에서의 우려도 당연히 있을 수 있다. LLM이 생성한 코드를 그냥 실행한다면 위험하지 않을까. smolagents는 이에 대해 E2B라는 서비스와의 통합을 통해 샌드박스 환경에서 코드를 격리 실행할 수 있는 옵션을 제공한다. 프로덕션 환경에서는 이를 활용하여 안전하게 운영할 수 있다.


smolagents의 장점들

smolagents가 내세우는 장점 중 가장 먼저 이야기해야 할 것은 역시 극단적인 단순함이다. 핵심 로직이 약 1,000줄이라는 것은 개발자가 프레임워크의 전체 동작 원리를 소스코드를 읽으며 파악할 수 있다는 뜻이다. 다른 프레임워크에서는 종종 "이 프레임워크가 내부적으로 대체 무슨 일을 하고 있는 거지?"라는 의문에 빠지게 되는데, smolagents에서는 그런 블랙박스가 거의 없다. 에이전트가 실패했을 때도 일반적인 Python 디버깅 방법을 그대로 적용하면 된다. 복잡한 추상화 뒤에 숨어 있는 버그를 추적할 필요가 없다.

알아야 할 개념도 적다. Agent, Tool, Model 이 세 가지만 이해하면 바로 에이전트를 만들 수 있다. Agent는 추론 루프를 관리하고, Tool은 에이전트가 사용할 수 있는 기능을 정의하며, Model은 어떤 LLM을 사용할지 지정한다. Python 기본 지식만 있으면 시작할 수 있으며, 공식 문서도 간결하고 예제 중심이라 빠르게 따라갈 수 있다.

LLM 선택의 유연성도 큰 장점이다. smolagents는 특정 모델이나 서비스에 종속되지 않도록 설계되었다. TransformersModel을 사용하면 로컬에서 오픈소스 모델을 돌릴 수 있고, InferenceClientModel을 쓰면 Hugging Face의 서버리스 추론 API를 활용할 수 있다. LiteLLMModel은 OpenAI, Anthropic, Google 등 거의 모든 상용 LLM 서비스를 지원하며, OpenAIServerModel은 OpenAI API 호환 인터페이스를 제공하는 어떤 서비스와도 연결할 수 있다. 모델을 바꾸고 싶을 때 model_id 한 줄만 수정하면 되니, 실험과 전환이 매우 편리하다.

Hugging Face Hub과의 통합도 인상적이다. 직접 만든 도구를 push_to_hub으로 Hub에 공유할 수 있고, 다른 사람이 만든 도구를 load_tool로 바로 가져다 쓸 수 있다. Gradio Spaces를 도구로 활용하는 것도 가능하다. 에이전트 프레임워크의 가치는 결국 얼마나 다양하고 유용한 도구를 쉽게 연결할 수 있느냐에 달려 있는데, Hub 통합은 이 측면에서 smolagents에게 강력한 무기가 된다.

스트리밍 지원도 실용적인 장점이다. agent.run(prompt, stream=True)로 호출하면 에이전트의 각 스텝을 ActionStep과 FinalAnswerStep 이벤트로 순차적으로 받을 수 있다. 사용자에게 에이전트가 지금 무엇을 생각하고 있고 어떤 도구를 호출했는지를 실시간으로 보여줄 수 있어서, 긴 추론 과정에서도 사용자 경험을 개선할 수 있다.

도구를 정의하는 방식도 직관적이다. 간단한 도구는 @tool 데코레이터를 함수에 붙이기만 하면 되고, DB 세션 같은 외부 의존성이 필요한 복잡한 도구는 Tool 클래스를 상속받아 만들면 된다. 클래스 방식에서는 name, description, inputs, output_type을 클래스 변수로 정의하고 forward 메서드에 실제 로직을 구현한다. description에 도구의 동작 방식과 제약 사항을 상세히 적어두면 LLM이 그 설명을 읽고 올바르게 도구를 활용한다.


ETF Atlas 프로젝트에서의 활용

이론적인 장점을 알았으니, 실제 프로젝트에서 smolagents가 어떻게 쓰였는지 살펴보자. ETF Atlas는 한국 ETF 시장 데이터를 수집하고 분석하고 시각화하는 플랫폼이다. 이 프로젝트의 특징 중 하나는 Apache AGE라는 그래프 데이터베이스를 활용하여 ETF와 보유 종목 간의 관계를 그래프로 모델링한다는 점이다. "삼성전자를 가장 많이 보유한 ETF는?" 같은 질문에 답하려면 ETF-종목 관계를 탐색해야 하는데, 그래프 DB가 이런 관계형 질의에 적합하다. 여기에 사용자가 자연어로 질문을 던지면 AI가 알아서 적절한 쿼리를 만들어 답변하는 챗봇 기능을 추가하고 싶었고, 이 챗봇의 엔진으로 smolagents를 선택했다.

전체 아키텍처는 이렇다. 사용자가 React로 만든 프론트엔드 채팅 인터페이스에서 질문을 입력하면, FastAPI 백엔드로 요청이 전달되고, 백엔드의 ChatService가 smolagents의 CodeAgent를 실행한다. CodeAgent는 자신이 가진 8개의 커스텀 도구 중 필요한 것을 선택해서 PostgreSQL과 Apache AGE 그래프 DB에 접근하고, 결과를 종합하여 답변을 만들어낸다. 이 과정에서 LiteLLMModel을 통해 OpenAI의 gpt-4.1-mini 모델이 추론을 담당한다.

8개의 커스텀 도구는 각각 다른 역할을 맡고 있다. 가장 핵심적인 것은 CypherQueryTool인데, Apache AGE 그래프 데이터베이스에 Cypher 쿼리를 직접 실행하는 도구다. 이 도구의 description에는 그래프의 전체 스키마가 담겨 있다. ETF, Stock, Tag라는 노드 유형이 있고, HOLDS와 HAS_TAG라는 관계가 있으며, 각각 어떤 속성을 가지고 있는지가 상세히 기술되어 있다. LLM은 이 설명을 읽고 적절한 Cypher 쿼리를 Python 코드 안에서 생성하여 실행한다. ETFSearchTool과 StockSearchTool은 각각 ETF와 주식 종목을 이름이나 코드로 검색하는 도구이고, ListTagsTool은 사용 가능한 태그(반도체, 배당, 2차전지 등) 목록을 조회한다. FindSimilarETFsTool은 TF-IDF 유사도를 기반으로 보유 종목 구성이 비슷한 ETF를 찾아주고, GetETFInfoTool은 특정 ETF의 종합 정보를 한꺼번에 가져온다. GetHoldingsChangesTool은 보유 종목의 비중 변화를 추적하며, GetETFPricesTool은 가격 추이와 통계를 조회한다.

모든 도구는 Tool 클래스를 상속하는 방식으로 구현했다. @tool 데코레이터 대신 클래스 방식을 선택한 이유는 DB 세션을 생성자 주입으로 관리하기 위해서다. 각 도구의 __init__에서 DB 세션을 받아두고, forward 메서드에서 이를 활용한다. 결과는 항상 json.dumps로 직렬화하되, ensure_ascii=False를 지정하여 한글이 깨지지 않도록 했다.

시스템 프롬프트는 한국어로 작성했다. "당신은 ETF Atlas의 AI 어시스턴트입니다"로 시작하며, 각 도구의 용도와 사용 순서를 안내한다. 예를 들어 사용자가 종목명을 언급하면 먼저 stock_search로 코드를 확인하고, 태그나 테마가 나오면 list_tags로 정확한 태그명을 파악한 뒤, 확인된 코드나 태그명으로 cypher_query를 실행하라는 식이다. 답변은 반드시 한국어로 하고, 비중은 퍼센트로 표시하며, 반드시 final_answer()를 호출하여 최종 답변을 반환하라는 규칙도 포함되어 있다.

스트리밍 구현이 특히 잘 맞아떨어진 부분이다. 백엔드에서는 agent.run(prompt, stream=True)로 호출하고, 각 이벤트를 Server-Sent Events(SSE) 형식으로 프론트엔드에 전달한다. ActionStep 이벤트가 오면 에이전트가 어떤 코드를 실행했고 어떤 관찰 결과를 얻었는지를, FinalAnswerStep이 오면 최종 답변을 보낸다. 프론트엔드에서는 fetch API와 ReadableStream으로 이 SSE를 수신하고, 각 스텝을 접이식 UI 컴포넌트로 보여준다. 사용자는 에이전트가 "먼저 삼성전자의 종목 코드를 검색하고, 그 다음 Cypher 쿼리로 보유 ETF를 조회했다"는 사고 과정을 실시간으로 따라갈 수 있다. AbortController를 통해 응답 도중 취소하는 것도 가능하다.

대화 히스토리 관리도 실용적으로 처리했다. 이전 대화를 모두 컨텍스트에 넣으면 토큰 비용이 빠르게 증가하므로, 최근 10개 메시지만 포함하도록 제한했다. 에러 처리에도 신경을 썼는데, 에이전트가 final_answer()를 호출하지 못한 경우에는 마지막으로 관찰한 결과를 답변으로 대체하고, 그마저도 없으면 "죄송합니다. 답변 생성에 실패했습니다"라는 폴백 메시지를 보여준다. 관찰 결과는 2,000자로 잘라서 UI 성능이 저하되지 않도록 했다.

실제로 이 챗봇은 꽤 다양한 질문을 처리할 수 있다. "삼성전자를 가장 많이 보유한 ETF는?"이라고 물으면 에이전트는 먼저 stock_search로 삼성전자의 종목 코드를 찾고, cypher_query로 해당 종목을 보유한 ETF들을 비중 순으로 조회한다. "반도체 관련 ETF 목록 보여줘"라고 하면 list_tags로 반도체 관련 태그를 확인한 뒤 cypher_query로 해당 태그가 붙은 ETF들을 찾는다. "KODEX 200과 비슷한 ETF는?"이라고 물으면 etf_search로 코드를 확인하고 find_similar_etfs를 호출한다. 이 모든 과정에서 CodeAgent가 Python 코드로 도구 호출을 체이닝하기 때문에, 여러 도구를 자연스럽게 조합하는 것이 가능하다.

전체 챗봇 기능이 단일 파일인 chat_service.py 약 470줄에 담겨 있다는 점도 언급할 만하다. 8개의 도구 정의, 시스템 프롬프트, 에이전트 초기화, 스트리밍/비스트리밍 실행 로직, 스텝 추출, 에러 처리까지 모두 포함해서 이 분량이다. smolagents의 단순함 덕분에 프레임워크와 씨름하는 시간을 줄이고, 실제 비즈니스 로직에 집중할 수 있었다.


smolagents와 LangChain 비교

이제 AI 에이전트 프레임워크의 대표 주자인 LangChain과 비교해보자. 두 프레임워크는 같은 문제를 해결하려고 하지만 접근 방식이 근본적으로 다르다. 한마디로 요약하면, smolagents는 "작고 날카로운 칼"이고 LangChain은 "스위스 아미 나이프"다.

설계 철학부터 다르다. smolagents는 "단순함이 최고의 가치"라는 원칙 아래 최소한의 추상화와 최소한의 코드를 추구한다. 에이전트의 행동을 Python 코드로 직접 표현하며, "프로그래밍 언어야말로 컴퓨터의 행동을 기술하는 최적의 도구"라는 믿음을 갖고 있다. 반면 LangChain은 "모든 것을 연결하는 프레임워크"를 지향한다. Chain, Agent, Memory, Retriever, Prompt Template, Output Parser, Document Loader, Text Splitter, Vector Store 등 풍부한 추상화 계층을 제공하며, 이들을 모듈처럼 조합하여 다양한 파이프라인을 구성할 수 있게 해준다. 2022년에 출시된 LangChain은 이미 700개 이상의 통합(Integration)을 지원하는 거대한 생태계를 갖추고 있다.

에이전트 구현 방식의 차이가 가장 체감된다. smolagents에서 에이전트를 만들려면 CodeAgent에 도구 목록과 모델을 넘기고 run()을 호출하면 된다. 세 줄이면 충분하다. LLM이 Python 코드를 생성하고, 그 코드가 직접 실행되어 도구를 호출한다. JSON 파싱 과정이 없으니 중간에 파싱 에러가 날 일도 없다. LangChain에서는 도구를 정의하고, 프롬프트 템플릿을 만들고, create_tool_calling_agent로 에이전트를 생성하고, AgentExecutor로 감싼 뒤 invoke를 호출한다. LLM이 JSON 형태로 도구 호출을 정의하면 프레임워크가 이를 파싱하여 실행한다. 더 구조화되어 있고 예측 가능하지만, 표현력에서는 코드 기반 접근에 비해 제한이 있다.

도구 정의 방식은 사실 양쪽이 꽤 비슷하다. 둘 다 데코레이터 방식과 클래스 상속 방식을 지원한다. 차이점이라면 smolagents는 inputs 딕셔너리로 파라미터를 정의하는 반면, LangChain은 Pydantic 모델(args_schema)을 사용한다는 점이다. LangChain 쪽이 타입 검증이 더 엄격하고, smolagents 쪽이 더 가볍다고 볼 수 있다.

학습 곡선의 차이는 상당하다. smolagents는 Agent, Tool, Model이라는 세 가지 핵심 개념만 이해하면 바로 시작할 수 있다. 소스코드가 약 1,000줄이니 프레임워크 전체를 읽어보는 것도 현실적으로 가능하다. Python 기본 지식만 있으면 된다. LangChain은 알아야 할 개념이 훨씬 많다. Chain이 뭔지, Memory가 어떻게 작동하는지, Retriever와 Document Loader는 어떤 관계인지, Output Parser는 왜 필요한지를 이해해야 한다. 방대한 공식 문서가 있지만, 그 양 자체가 진입 장벽이 되기도 한다. 프레임워크 고유의 패턴과 관례를 익히는 데 상당한 시간이 필요하다.

생태계와 커뮤니티 측면에서는 LangChain이 압도적으로 앞서 있다. 2022년에 출시된 만큼 성숙한 생태계를 갖추고 있으며, LangSmith라는 모니터링/디버깅 도구, LangServe라는 배포 도구, LangGraph라는 복잡한 워크플로우 관리 도구까지 갖추고 있다. LangGraph는 노드와 엣지 기반의 그래프 구조로 에이전트 워크플로우를 정의하며, 루프, 조건 분기, 병렬 처리, 멀티 에이전트 협업 같은 고급 패턴을 지원한다. 상태 관리와 체크포인트 기능도 내장되어 있다. smolagents는 2025년에 출시된 신생 프레임워크로 아직 생태계가 작지만, Hugging Face Hub을 기반으로 빠르게 성장하고 있고, Hugging Face Agents Course라는 교육 과정도 제공하고 있다.

확장성 측면에서도 차이가 있다. smolagents는 단순한 에이전트 작업에 최적화되어 있다. 멀티 에이전트 구성도 가능하긴 하다. 에이전트를 다른 에이전트의 도구로 등록하는 방식인데, 기본적인 수준이다. 복잡한 워크플로우나 조건 분기, 병렬 처리가 필요하면 개발자가 코드로 직접 구현해야 한다. LangChain + LangGraph 조합은 이런 복잡한 시나리오를 프레임워크 수준에서 지원한다. 대규모 프로덕션 환경에서 여러 에이전트가 협업하고, 상태를 관리하고, 실패 시 복구하는 시스템을 만들어야 한다면 LangGraph가 더 적합할 것이다.

디버깅 경험도 다르다. smolagents에서는 에이전트가 생성한 Python 코드를 직접 읽고 디버깅한다. 스트리밍을 통해 각 스텝에서 어떤 코드가 실행되었고 어떤 결과가 나왔는지 실시간으로 확인할 수 있다. 문제가 생기면 해당 Python 코드를 따로 떼어내서 실행해보면 된다. LangChain에서는 LangSmith라는 시각적 도구를 통해 실행 트레이스를 확인할 수 있다. 그래프의 각 노드가 어떤 상태였는지를 시각적으로 보여주니 전체 흐름을 파악하기는 편하다. 하지만 추상화 계층이 여러 겹 쌓여 있어서, 특정 문제의 근본 원인을 찾아가는 과정이 때로는 복잡해질 수 있다.

그래서 어떤 것을 선택해야 할까. 결국 프로젝트의 성격에 달려 있다. 빠른 프로토타이핑이 필요하거나, 에이전트 시스템이 비교적 단순하거나, 팀 규모가 작아서 프레임워크 학습에 많은 시간을 쓰기 어렵거나, 에이전트의 내부 동작을 투명하게 이해하고 싶다면 smolagents가 좋은 선택이다. 반대로 복잡한 멀티 에이전트 워크플로우가 필요하거나, 엔터프라이즈급 프로덕션을 운영해야 하거나, RAG 파이프라인부터 모니터링까지 일관된 도구 체인이 필요하거나, 대규모 팀에서 표준화된 패턴으로 개발해야 한다면 LangChain이 더 적합하다.


ETF Atlas에서 smolagents를 선택한 이유

ETF Atlas 프로젝트에서 smolagents를 선택한 데에는 몇 가지 명확한 이유가 있었다. 첫째, 빠른 개발 속도가 필요했다. 챗봇은 프로젝트의 핵심 기능이 아니라 부가 기능이었기 때문에, 최소한의 노력으로 충분히 동작하는 결과물을 만들어내는 것이 중요했다. smolagents 덕분에 8개의 커스텀 도구와 전체 챗봇 로직을 단일 파일 약 470줄로 완성할 수 있었다.

둘째, CodeAgent의 도구 체이닝이 ETF 데이터 조회 패턴과 잘 맞았다. 대부분의 질문이 "먼저 이름으로 코드를 찾고, 그 코드로 상세 데이터를 조회하는" 멀티스텝 패턴을 따르는데, CodeAgent가 Python 코드로 이 체이닝을 자연스럽게 수행했다.

셋째, 스트리밍 구현이 간단했다. FastAPI의 StreamingResponse와 smolagents의 stream=True 옵션을 조합하는 것만으로 실시간 응답을 구현할 수 있었다. 에이전트의 사고 과정을 사용자에게 보여줌으로써, 응답을 기다리는 동안의 체감 시간을 줄일 수 있었다.

넷째, LLM 교체의 유연성이 보장되었다. LiteLLMModel을 사용하고 있어서, 현재 쓰고 있는 gpt-4.1-mini에서 다른 모델로 바꾸고 싶으면 model_id 한 줄만 수정하면 된다. 비용 최적화나 성능 개선을 위해 모델을 실험하기가 편리하다.

마지막으로, 프레임워크의 내부 동작을 완전히 이해한 상태에서 개발할 수 있다는 것이 큰 장점이었다. 문제가 생겼을 때 "이건 프레임워크 버그인가, 내 코드 문제인가"를 고민하지 않아도 되었다. 소스코드를 직접 확인하여 원인을 빠르게 파악하고 해결할 수 있었다.


마무리

smolagents는 "에이전트 프레임워크가 이렇게 간단할 수 있다"는 것을 증명한 프로젝트다. 약 1,000줄의 핵심 코드, 코드 퍼스트 접근, 유연한 모델 지원, Hugging Face Hub 통합이라는 무기로 AI 에이전트 개발의 진입 장벽을 크게 낮추었다. LangChain이 풍부한 생태계와 엔터프라이즈 기능으로 대규모 프로덕션 환경의 표준이 되고 있다면, smolagents는 단순함과 속도로 프로토타이핑과 중소규모 프로젝트의 최적 도구가 되고 있다.

ETF Atlas 프로젝트에서의 경험은 이를 잘 보여준다. 8개의 커스텀 도구와 스트리밍 챗봇을 효율적으로 구현했고, 특히 Apache AGE 그래프 데이터베이스와의 연동에서 CodeAgent의 유연한 코드 생성 능력이 빛을 발했다. 사용자에게 에이전트의 사고 과정을 실시간으로 보여주는 투명한 경험도 제공할 수 있었다. AI 에이전트 프레임워크를 처음 도입하는 프로젝트라면, smolagents는 훌륭한 출발점이 될 것이다. 가볍게 시작해서 필요에 따라 점진적으로 발전시켜 나갈 수 있다. 결국 좋은 도구란 문제를 해결하면서도 손에 잘 잡히는 도구이고, smolagents는 그런 도구에 가깝다.


참고 자료

- smolagents 공식 문서: https://huggingface.co/docs/smolagents/en/index
- smolagents GitHub: https://github.com/huggingface/smolagents
- smolagents 소개 블로그: https://huggingface.co/blog/smolagents
- Hugging Face Agents Course: https://huggingface.co/learn/agents-course/en/unit2/smolagents/introduction
- Why use smolagents: https://huggingface.co/learn/agents-course/unit2/smolagents/why_use_smolagents
- smolagents vs LangGraph 비교: https://www.analyticsvidhya.com/blog/2025/01/smolagents-vs-langgraph/
- AI Agent Framework 비교: https://langfuse.com/blog/2025-03-19-ai-agent-comparison
